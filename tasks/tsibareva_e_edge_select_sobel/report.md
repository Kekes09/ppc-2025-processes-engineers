# Выделение ребер на изображении с использованием оператора Собеля.

- Студент: Цибарева Екатерина Алексеевна, группа 3823Б1ПР1
- Технология: SEQ | MPI
- Вариант: 29

## 1. Введение
Задача свертки изображения с помощью ядер Собеля является одной из ключевых операций в области компьютерного зрения и обработки изображений. Она составляет вычислительное ядро алгоритмов выделения границ, определения направленных градиентов яркости и многих других методов анализа изображений. 

Целью данной работы является реализация, оптимизация и сравнительный анализ последовательного и параллельного алгоритмов свертки изображения с использованием операторов Собеля для обнаружения границ.

## 2. Постановка задачи
**Описание задачи**
Вычислить результирующее изображение путём применения к исходному изображению операции двумерной свертки с ядрами Собеля для выделения границ по направлению осей X и Y.

**Входной тип данных** 
- Вектор значений типа int (получаемый из текстового/бинарного файла в процессе эмуляции чтения исходного изображения в оттенках серого).
- Высота изображения.
- Ширина изображения.
- Значение threshold - порога обработки.

``` cpp
using InType = std::tuple<std::vector<int>, int, int, int>>;
```

**Выходной тип данных** 
- Вектор значений типа int, представляющий результат свертки.

``` cpp
using OutType = std::vector<int>;
```

**Ограничения**
- на вход должна быть подана не пустая матрица пикселей изображения в оттенках серого;
- предполагается стратегия обработки zero-padding (нулевой рамки), при которой изображение расширено на 2 пикселя в ширину и в высоту, - для того, чтобы после свертки размер результирующего изображения совпадал с размером исходного и ядра свертки могли быть применены к каждому пикселю;
- результаты, полученные в результате выполнения последовательного и параллельного алгоритма, не должны различаться;
- результат обработки должен совпадать с эталонным вектором (например, полученным через cv2.Sobel или аналогичным способом).

## 3. Описание базового алгоритма
**Основная идея**

Базовый последовательный алгоритм свёртки изображения ядром Собеля реализует прямое вычисление двумерной свёртки. Для каждого внутреннего пикселя исходного изображения вычисляется взвешенная сумма яркостей пикселей в окрестности 3x3, где весовые коэффициенты задаются ядрами Собеля (Gx для горизонтальных, Gy для вертикальных).

Шаги базового алгоритма обработки:

1. Инициализация данных: загрузка входного изображения (вектора пикселей) и определение его размеров. Установка значения threshold для частичной пороговой обработки результата.
2. Подготовка выходного буфера: инициализация выходного вектора нулевыми значениями размером height_ × width_.
3. Последовательное вычисление градиентов: Алгоритм предполагает последовательный обход всех пикселей изображения:
   Для каждого пикселя с координатами (row, col):
   - Вычисляется горизонтальная составляющая градиента GradientX путём свёртки с ядром Собеля по оси X
   - Вычисляется вертикальная составляющая градиента GradientY путём свёртки с ядром Собеля по оси Y
   - Вычисляется магнитуда градиента: mag = sqrt(gx^2 + gy^2)
   - Применяется пороговая обработка: если полученное значение не больше порогового, значение устанавливается в 0
4. Обработка границ: В методах GradientX и GradientY реализована обработка граничных пикселей через проверку выхода за пределы изображения.

Вычислительная сложность алгоритма составляет O(H × W × K^2), где:
H — высота изображения
W — ширина изображения
K — размер ядра (K = 3 для ядер Собеля)

Частичный код базового (последовательного) алгоритма можно видеть ниже.

``` cpp
bool TsibarevaEEdgeSelectSobelSEQ::RunImpl() {
  const auto &flat_pixels = std::get<0>(GetInput());
  input_pixels_ = std::vector<int>(flat_pixels);

  auto &output_pixels = GetOutput();

  for (int row = 0; row < height_; ++row) {
    for (int col = 0; col < width_; ++col) {
      int gx = GradientX(col, row);
      int gy = GradientY(col, row);

      int mag = static_cast<int>(std::sqrt((gx * gx) + (gy * gy) + 0.0));
      output_pixels[(static_cast<size_t>(row) * width_) + col] = (mag <= threshold_) ? 0 : mag;
    }
  }
  return true;
}
```
Где вычисление градиента по оси X, например, выглядит следующим образом:
``` cpp
int TsibarevaEEdgeSelectSobelSEQ::GradientX(int x, int y) {
  int sum = 0;
  for (int ky = -1; ky <= 1; ++ky) {
    for (int kx = -1; kx <= 1; ++kx) {
      int nx = x + kx;
      int ny = y + ky;

      int weight = kSobelX[ky + 1][kx + 1];

      if (nx >= 0 && nx < width_ && ny >= 0 && ny < height_) {
        sum += weight * input_pixels_[(static_cast<size_t>(ny) * width_) + nx];
      }
    }
  }
  return sum;
}
```

## 4. Схема распараллеливания
**Модель распределения**

Для распараллеливания задачи применяется горизонтальное ленточное разбиение по строкам изображения с учетом гало-областей или гало-строк (строк сверх обрабатываемых, необходимых для ядра свертки). Исходное изображение делится на непрерывные горизонтальные полосы, каждая из которых назначается отдельному MPI-процессу.

При этом, при делении высоты изображения H на количество процессов P каждый процесс получает base_rows = H / P строк, а первые remainder = H % P процессов получают дополнительную строку.
Для корректного вычисления свертки ядрами 3 на 3, каждому процессу передаются основные строки — строки для непосредственной обработки, верхняя гало-строка — если процесс не является первым, нижняя гало-строка — если процесс не является последним. Присутствие верхней и нижней вспомогательной строки определяется флагами.

**Роли процессов**

Процесс 0 выступает в роли координатора:
- принимает входные данные и параметры задачи;
- рассылает параметры всем процессам через MPI_Bcast;
- рассчитывает и распределяет строки изображения между процессами с учётом гало-областей;
- собирает локальные результаты со всех процессов и формирует итоговое изображение.

Процессы рангом 1 и выше:
- выполняют локальные свертки в назначенных и разосланных им полосах (множестве строк) с учетом полученных гало-строк (что делает возможным обработку даже матрицы изображения, состоящей из одной строки);
- передают результаты локальных вычислений процессу с рангом 0.

**Коммуникационная схема**

**Шаги параллельного алгоритма обработки**: 
1. Распространение параметров задачи: все процессы получают размеры изображения и пороговое значение через MPI_Bcast.

2. Расчет локальных параметров распределения: вычисление базового (без учета гало-строк) количества строк для обработки, необходимости верхней/нижней гало-строк, общего размера локального буфера с гало-областями.

3. Распределение данных: рассчет процессом 0 смещения и размеров данных для каждого процесса и распределение частей изображения через MPI_Scatterv.

4. Локальное вычисление градиентов: вычисление градиентов Собеля для своих строк каждым процессом локально (вычисление градиентов по оси X, Y, частичная пороговая обработка, при которой значения ниже порога зануляются).
   Необходимо заметить, что пороговая обработка в разных практических задачах может быть реализована индивидуально, в задаче выделения границ чаще требуется затемнить фон результирующего изображения и сделать более светлыми края.

5. Сбор и синхронизация результатов на всех процессах посредством MPI_Allgatherv.

6. Формирование выходных данных в GetOutput() на каждом процессе.

**Особенности модели распределения и коммуникационной схемы**:
- распределение данных матрицы между процессами по строкам, топология "звезда" (нулевой процесс, как координатор, рассылает данные на все процессы);
- отказ от способа получения гало-строк от процессов-соседей (у которых ранг на 1 больше либо меньше текущего) в пользу первоначальной рассылки дополнительных строк там, где они требуются; что было реализовано посредством введения простой системы флагов, позволяющей производить рассчет итогового числа строк на процесс;
- устойчивость к возникновению граничных случаев: совокупность модели zero-padding и модели предварительной рассылки гало-строк делают возможной штатную обработку матриц, состоящих из единственной строки/столбца;
- выполнение распределения, рассылок и формирования результата первично - на нулевом (координаторском) процессе;
- эффективный сбор и синхронизация данных на всех процессах одновременно.

## 5. Детали реализации

**Структура проекта**
``` text
tsibareva_e_edge_select_sobel
        │   info.json
        │   report.md
        │   settings.json
        ├───common
        │   └───include
        │           common.hpp
        ├───data
        │       pic.jpg
        ├───mpi
        │   ├───include
        │   │       ops_mpi.hpp
        │   │
        │   └───src
        │           ops_mpi.cpp
        ├───seq
        │   ├───include
        │   │       ops_seq.hpp
        │   │
        │   └───src
        │           ops_seq.cpp
        └───tests
            │   .clang-tidy
            │
            ├───functional
            │       main.cpp
            └───performance
                    main.cpp
```

Проект реализации исходных алгоритмов, функционального тестирования и тестирования производительности имеет сложную структуру. 

**Файлы реализаций**

1. Последовательная реализация (seq):

- ops_seq.hpp — объявление класса TsibarevaEEdgeSelectSobelSEQ, содержащего обязательные для переопределения методы (RunImpl(), PreProcessingImpl(), PostProcessingImpl(), ValidationImpl()), методы вычисления свертки соответствующими ядрами Собеля, массив локальных данных, а также, для удобства, глобально объявленные переменные высоты, ширины и порогового значения.

- ops_seq.cpp — реализация методов:
    - RunImpl()            — базовый последовательный алгоритм свёртки с ядрами Собеля;
    - PreProcessingImpl()  — инициализация выходного вектора;
    - PostProcessingImpl() — не предполагает отдельной логики;
    - ValidationImpl()     — не предполагает отдельной логики;
    - GradientX() и GradientY() — методы вычисления свёртки с соответствующими ядрами Собеля.

2. MPI реализация (mpi):

- ops_mpi.hpp — объявление класса TsibarevaEEdgeSelectSobelMPI, содержащего обязательные для переопределения методы (RunImpl(), PreProcessingImpl(), PostProcessingImpl(), ValidationImpl()), поля для данных (input_pixels_ - исходное изображение, local_pixels_ - локальная часть данных с учетом гало-областей), а также вспомогательные методы для распределения данных и вычислений.

- ops_mpi.cpp — реализация методов:
    - BroadcastParameters()      — распространение размеров изображения и порога на все процессы;
    - RowDistributionComputing() — вычисление параметров распределения строк для текущего процесса;
    - DistributeRows()           — распределение строк изображения между процессами с учётом гало-областей;
    - LocalGradientsComputing()  — вычисление градиентов для локальной части изображения;
    - GatherResults()            — сбор частичных результатов со всех процессов;
    - GradientX() и GradientY()  — методы вычисления свёртки с соответствующими ядрами Собеля.

Оба файла реализации (MPI и SEQ) предполагают использование заранее заданных ядер Собеля:
``` cpp
const std::vector<std::vector<int>> kSobelX =
                                        {{-1, 0, 1},
                                         {-2, 0, 2},
                                         {-1, 0, 1}};

const std::vector<std::vector<int>> kSobelY =
                                        {{-1, -2, -1},
                                         { 0,  0,  0},
                                         { 1,  2,  1}};
```

**Тестирование и формирование входных данных**

3. Общие компоненты (common):
- common.hpp содержит:
    - объявление входного (InType), выходного (OutType) типа, типа базовой задачи (BaseTask) и тестовых классов (TestTask); необходимо отметить, что входные данные представлены в формате плоского вектора, выходные - плоского результирующего вектора; 
    ``` cpp
    using InType = std::tuple<std::vector<int>, int, int, int>;  
    using OutType = std::vector<int>;
    using TestType = std::tuple<ImageType, std::string>;
    using BaseTask = ppc::task::Task<InType, OutType>;
    ``` 
    - перечисление типов изображений от kTest1 до kTest7, причем каждому типу соответствует файл .txt, чтение которого эмулирует чтение бит изображения в оттенках серого;
    - функцию ReadImageFile(const std::string &filename), эмулирующую чтение изображения из файла;
      необходимо отметить, что, хотя требованием к используемым входным данным не было установлено чтение изображения в обязательном порядке, функция ReadImageFile представляет из себя изолированный с точки зрения ООП блок чтения изображения и преобразования его в плоский вектор целочисленных значений;
    - функцию GenerateTestData(ImageType type), выполняющую формирование наборов тестовых данных из полученного вектора, размеров исходного изображения, порогового значения выделения границ;
    - функцию GenerateExpectedOutput(ImageType type), выполняющую формирование эталонных данных для сравнения с результирующим вектором после выполнения алгоритма;
    - вспомогательную функцию GetDirectoryPath(const std::string &full_path), позволяющую корректно получить путь к исходным файлам, используя константу PPC_SETTINGS_tsibareva_e_edge_select_sobel (поскольку упомянутая константа содержит путь до внешнего json-файла, требуется незначительная корректировка).

**Формирование входных данных** таким образом может быть поделено на считывание (и запись в плоский вектор) и формирование набора данных. При этом исходный файл предполагает следующую структуру: 
```
<высота изображения>
<ширина изображения>
<матричное представление изображения в оттенках серого>
```
А пороговое значение может быть скорректировано при необходимости. 

Генерация эталонных данных была произведена внешним скриптом (библиотеками языка программирования python) при использовании аналогичного, но стандартизированного в библиотеках языка алгоритма свертки ядрами Собеля.

4. Функциональные тестовые файлы (tests/funtional):
- main.cpp - содержит:
    - объявление класса TsibarevaERunFuncTestsProcesses;
    - переопределение функции PrintTestParam таким образом, что печать тестов содержит краткое описание её типа;
    - переопределение функции SetUp таким образом, чтобы входные данные могли быть подготовлены функцией GenerateTestData, а эталонные - функцией GenerateExpectedOutput напрямую, посредством явного указания типа требуемого в тесте изображения;
    ``` cpp
    ImageType image_type = std::get<0>(params);
    input_data_ = GenerateTestData(image_type);
    expected_output_ = GenerateExpectedOutput(image_type);
    ```
    При этом каждому типу изображения заведомо соответствует файл его расположения.

5. Тестовые файлы производительности (tests/performance):
- main.cpp - содержит:
    - объявление класса TsibarevaERunPerfTestProcesses;
    - переопределение функции SetUp, предполагающее генерацию тестового плоского вектора, эмулирующего изображение в оттенках серого; отказ от реализации нагрузочного тестирования на реальных наборах данных обусловлен недостаточными размерами большинства стандартных изображений, а отказ от генерации сторонними скриптами с последующим чтением, аналогично функциональному тестированию - значительными (свыше 20Гб) размерами исходных файлов.

Для тестирования производительности были сгенерированы псевдослучайные наборы данных, содержащие вертикальные, горизонтальные, диагональные полосы. Тестирования производилось на "изображении" в 9 миллионов пикселей.

## 6. Экспериментальные результаты

**Аппаратное обеспечение и характеристики ОС локального запуска**:
- Модель процессора: AMD Ryzen 7 5700U (1.80 GHz)
- Архитектура: x86-64
- Ядра: 8 ядер
- Оперативная память: 8 GB
- Операционная система: Windows 10 Home (базовая) / Ubuntu 24.04.3 LTS (сборочная)
- Подсистема: WSL2 (Windows Subsystem for Linux)

**Инструменты**:
- Компилятор: GCC 13.3.0 (Ubuntu 13.3.0-6ubuntu2~24.04)
- MPI реализация: Open MPI 4.1.6
- Тип сборки: Release 

**Настройки окружения**:
- PPC_NUM_PROC: 2 (количество MPI процессов)
- PPC_NUM_THREADS: 4 (доступные потоки)
- Количество доступных процессов PPC_NUM_PROC также может быть задано ключом ``` mpirun -n M ``` при запуске тестов, где M - требуемое количество процессов.

## 7. Результаты и обсуждение

### 7.1 Корректность
Для проверки корректности были сгенерированы наборы данных среднего (10 на 10), большого (20 на 20), малого (5 на 5) размеров, прямоугольные "изображения" (в котором больше строк чем столбцов, больше столбцов чем строк), "изображение" размера, меньшего чем размер ядра свертки (2 на 2), размера, соответствующего размеру ядра свертки (3 на 3), "изображения", представленного диагональной матрицей, содержащего вертикальную, горизонтальную широкие и диагональную полосы.

Так, например, файл "изображения" (10 на 10 пикселей, при значении пикселя в пределах [0, 255]), заполненного случайным образом, может выглядеть так:
```
10
10
696 610 563 451 501 523 565 601 589 622
782 413 183 0   116 0   101 161 102 621
404 471 265 148 242 106 0   139 0   667
248 0   437 359 183 146 174 204 0   684
251 136 236 387 509 210 311 0   105 608
129 130 113 204 487 705 255 362 0   556
140 0   204 214 334 848 614 132 158 629
110 163 0   0   154 257 661 513 243 654
204 275 276 176 130 183 177 461 326 518
296 213 185 249 306 271 223 357 508 452
```
Всего было подготовленно 7 тестовых наборов данных, покрывающих по несколько основных тестовых случаев каждый.

### 7.2 Производительность
Тесты производительности были проведены локально на 9 миллионах пикселей (элементов соответствующей матрицы).

### Режим Pipeline
| Процессов | Время, с | Ускорение | Эффективность |
|-----------|----------|-----------|---------------|
| 1 (SEQ)   | 0.2040   | 1.00      | N/A           |
| 1 (MPI)   | 0.1829   | 1.12      | 112%          |
| 2 (MPI)   | 0.0993   | 2.05      | 103%          |
| 3 (MPI)   | 0.0960   | 2.13      |  71%          |
| 4 (MPI)   | 0.0846   | 2.41      |  60%          |
| 6 (MPI)   | 0.0853   | 2.39      |  40%          |
| 8 (MPI)   | 0.1028   | 1.98      |  25%          |

### Режим Task Run  
| Процессов | Время, с | Ускорение | Эффективность |
|-----------|----------|-----------|---------------|
| 1 (SEQ)   | 0.1964   | 1.00      | N/A           |
| 1 (MPI)   | 0.1733   | 1.13      | 113%          |
| 2 (MPI)   | 0.1089   | 1.80      |  90%          |
| 3 (MPI)   | 0.1112   | 1.77      |  59%          |
| 4 (MPI)   | 0.0948   | 2.07      |  52%          |
| 6 (MPI)   | 0.1057   | 1.86      |  31%          |
| 8 (MPI)   | 0.1026   | 1.91      |  24%          |

MPI реализация показала ускорение до 2.41 раза относительно последовательной реализации алгоритма в pipeline режиме на 4 процессах. Наблюдается линейное ухудшение эффективности, обусловленное ростом накладных расходов с увеличением количества процессов.

## 8. Выводы
В ходе работы были успешно реализованы последовательный и параллельный (на основе MPI) алгоритмы свёртки изображения с использованием операторов Собеля для выделения границ. Была разработана система тестирования с различными типами тестовых изображений и выполнены замеры производительности (ускорения и эффективности) распараллеливания.

Параллельная реализация демонстрирует ожидаемое ускорение до 2.41 раз относительно последовательной реализации алгоритма.

## 9. Источники

1. **Технологии параллельного программирования MPI и OpenMP** // А.В. Богданов, В.В. Воеводин и др., - МГУ, 2012.
2. **Инструменты параллельного программирования в системах с общей памятью: Учебное пособие.** // Корняков К.В., Мееров И.Б., Сиднев А.А., Сысоев А.В., Шишков А.В., - Нижний Новгород: Изд-во Нижегородского госуниверситета, 2010. - 202 с.
3. **Справочник по MPI** // URL: https://learn.microsoft.com/ru-ru/message-passing-interface/mpi-reference, 2023 (дата обращения: 15.11.2025).
4. **Open MPI: Open Source High Performance Computing** // URL: https://www-lb.open-mpi.org/doc/v4.1, 2025 (дата обращения: 15.11.2025).