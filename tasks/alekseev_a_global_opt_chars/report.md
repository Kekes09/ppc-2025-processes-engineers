# Многошаговая схема решения двумерных задач глобальной оптимизации. Распараллеливание по характеристикам

- **Студент:** Алексеев Артемий Алексеевич, группа 3823Б1ПР2
- **Технология:** SEQ | MPI
- **Вариант:** №13

## 1. Введение

**Цель работы:** Цель работы: реализовать последовательную и параллельную (MPI) версии алгоритма глобальной оптимизации функции двух переменных на прямоугольной области на основе многошаговой схемы редукции размерности и характеристического подхода (по Стронгину), а также провести сравнение производительности.

**Задачи:**
1. Реализовать SEQ-версию алгоритма глобального поиска в 2D через редукцию 2D→1D.
2. Реализовать MPI-версию с распараллеливанием вычисления характеристик интервалов.
3. Сравнить производительность SEQ и MPI реализаций.

## 2. Постановка задачи

Задача: найти приближённое решение для многоэкстремальной функции, заданной как «чёрный ящик».

**Описание метода решения:** 
- Параметризуем 2D область одним параметром t с помощью кривой заполнения пространства (Пеано).
- Получаем одномерную задачу глобального поиска по t:
- Для 1D задачи используем характеристический алгоритм (информационно-статистический подход Стронгина): на каждом шаге выбирается интервал с максимальной характеристикой и вычисляется новая точка испытания.
**Входные данные:**
- func — целевая функция double f(double x, double y)
- границы области x_min, x_max, y_min, y_max
- epsilon — точность остановки по длине выбранного интервала в t-пространстве
- r_param — параметр надёжности (должен быть `> 1`)
- max_iterations — ограничение на число итераций

**Выходные данные:**
- x_opt, y_opt — найденная точка минимума
- func_min — значение функции в найденной точке
- iterations — число итераций
- converged — флаг достижения условия остановки 

**Ограничения:** 
- func != nullptr
- x_min < x_max, y_min < y_max
- epsilon > 0
- r_param > 1
- max_iterations > 0


## 3. Описание алгоритма (последовательного)
**Алгоритм последовательного вычисления:**
1. Инициализация двумя испытаниями в точках t=0 и t=1.
2. На каждой итерации:
   1) сортировка испытаний по t;  
   2) оценка константы Липшица по текущим данным
   3) вычисление характеристик для всех интервалов
   4) выбор интервала с максимальной характеристикой
   5) вычисление новой точки испытания по формуле Стронгина
   6) остановка, если длина выбранного интервала меньше epsilon


## 4. Схема распараллеливания (MPI)
**Алгоритм параллельного вычисления:**
1. Root (rank 0) хранит общий список точек испытаний t_points_ и значений trial_points_
2. На каждой итерации root рассылает текущее состояние всем процессам (BroadcastTrialData())
3. Все процессы выполняют сортировку и оценку L одинаково (данные одинаковые)
4. Массив интервалов делится между процессами (через MPI_Scatterv), каждый процесс вычисляет локальные характеристики
5. Локальные характеристики собираются на root (Send/Recv), после чего root рассылает полный массив характеристик всем (MPI_Bcast)
6. Выбирается лучший интервал, root вычисляет новую точку испытания (вычисление func) и добавляет её в общий список
7. Проверка остановки и переход к следующей итерации

Таким образом распараллеливание реализует именно “распараллеливание по характеристикам”: каждый процесс обслуживает подмножество интервалов и вычисляет их (R_i).

## 5. Детали реализации
### 5.1. Структура реализации
```text
alekseev_a_global_opt_chars
    ├───common
    │   └───include
    │           common.hpp - определение типов входных/выходных/тестовых данных
    │
    ├───mpi
    │   ├───include
    │   │       ops_mpi.hpp - заголовочный файл MPI-реализации
    │   │
    │   └───src
    │           ops_mpi.cpp - код MPI-реализации
    │
    ├───seq
    │   ├───include
    │   │       ops_seq.hpp - заголовочный файл SEQ-реализации
    │   │
    │   └───src
    │           ops_seq.cpp - код SEQ-реализации
    │
    └───tests
        ├───functional
        │       main.cpp - функциональные тесты
        │
        └───performance
                main.cpp - тесты производительности
```
### 5.2. Основные классы / функции
- `AlekseevAGlobalOptCharsSEQ` - последовательная реализация
- `AlekseevAGlobalOptCharsMPI` - параллельная реализация
### 5.3. Пространственная и временная сложности алгоритмов
- Последовательная версия:
    - Временная сложность - `O(N)`, где `N` - кол-во итераций;
    - Пространственная сложность - `O(N)`, где `N` - кол-во итераций.
- Параллельная версия:
    - Временная сложность - `O(N)`, где `N` - кол-во итераций;
    - Пространственная сложность - `O(N)`, где `N` - кол-во итераций.
## 6. Экспериментальная среда
### 6.1. Аппаратное обеспечение:
| Параметр | Значение                                                                               |
| -------- | -------------------------------------------------------------------------------------- |
| CPU      | Ryzen 5 5600                                                                           |
| RAM      | 16 GB DDR4                                                                             |     
### 6.2. Программное обеспечение:
| Параметр   | Значение                                               |
| ---------- | ------------------------------------------------------ |
| ОС         | Windows 11 Home + WSL                                  |
| MPI        | OpenMPI 3.1                                            |
| Компилятор | g++ 14.2.0                                             |
| Сборка     | Release                                                |
### 6.3. Тестовые данные
**Функциональные тесты:**\
6 функций (Sphere, Quadratic, Matyas, Booth, Himmelblau, Rastrigin) с проверкой, что результат корректен и находится внутри области.
**Тесты производительности:**
функция Ellipsoid f(x,y) = 2x2 + 0.5y2 параметры: область [-6,6] [-6,6], epsilon=0.0002, r_param=2.2, max_iterations=2500.
## 7. Результаты и обсуждение

### 7.1 Корректность
Проверка корректности реализована средствами Google Test:
- 20 функциональных тестов покрывают различные ситуации.
- Perf-тест проверяет, что результат валиден.

Реализация успешно проходит как функциональные тесты, так и перф-тесты.

### 7.2 Производительность
**Метрики:**
1. Абсолютное время выполнения вычислительной части алгоритма в миллисекундах;
2. Ускорение относительно последовательной версии;
3. Эффективность распараллеливания = `(ускорение / число процессов) * 100%`.

**Полученные результаты:**

| **Режим** | **Количество процессов** | **Время, с** | **Speedup** | **Efficiency** |
|-----------|--------------------------|--------------|-------------|----------------|
| SEQ       | 1                        | 0.1225       | 1.00        | N/A            |
| MPI       | 2                        | 0.1607       | 0.71        | 35%            |
| MPI       | 4                        | 0.1521       | 0.74        | 18,7%          |
| MPI       | 8                        | 0.2034       | 0.55        | 7,1%           |

## 8. Заключение
В рамках данной работы были успешно реализованы: последовательная версия многошаговой схемы глобальной оптимизации 2D задачи через редукцию размерности 2D→1D (Peano-like mapping) и характеристический выбор интервалов;
MPI версия, где распараллелен расчёт характеристик интервалов (распараллеливание по характеристикам).
Реализации проходят функциональные и performance-тесты. Показано, что для простых функций MPI может проигрывать из-за коммуникаций, однако схема распараллеливания корректна и является базой для задач с дорогостоящими вычислениями целевой функции.

## 9. Источники
1. [Презентация по курсу](https://learning-process.github.io/parallel_programming_slides/)
2. Стронгин Р.Г. Численные методы в многоэкстремальных задачах. М.: Наука, 1978.
3. Гришагин В.А., Исрафилов Р.А. Параллельная реализация адаптивной многошаговой схемы редукции размерности для задач глобальной оптимизации (Russian Supercomputing Days 2017).